{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "entire-wildlife",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np; import random; import fractions; import math\n",
    "from matplotlib import pyplot, patches\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "N_FEATURES=2; MIN_CENTERS=2; MAX_CENTERS=20\n",
    "\n",
    "class Sample: \n",
    "    def __init__(self, n_samples, n_centers=3): \n",
    "        self.n_samples = n_samples\n",
    "        self.n_centers = n_centers\n",
    "    def _assign_positions(self, positions):\n",
    "        self.positions = positions\n",
    "        return\n",
    "    def _assign_labels(self, labels):\n",
    "        self.labels = labels\n",
    "        return\n",
    "    def reseed(self, new): \n",
    "        self.n_centers=new\n",
    "        return\n",
    "    def create_samples(self):\n",
    "        pass   \n",
    "class Normal_Blobs_Full(Sample): \n",
    "    def _semi_symm(self, n_dim_sqmat):  \n",
    "        rng = np.random.default_rng()\n",
    "        raw_mat = rng.uniform(low=0.0, high=0.1, size=(n_dim_sqmat, n_dim_sqmat))\n",
    "        symm_mat = (raw_mat + np.transpose(raw_mat))/2 \n",
    "        symm_semi_def_mat = np.dot(symm_mat, np.transpose(symm_mat))\n",
    "        return symm_semi_def_mat\n",
    "    def _assign_set_covariaces(self, set_cvmat): \n",
    "        self.set_cvmat = set_cvmat\n",
    "        return \n",
    "    def _assign_set_means(self, set_means): \n",
    "        self.set_means = set_means\n",
    "        return\n",
    "    def assign_set_obliques(self, set_thetas): \n",
    "        self.set_thetas = set_thetas \n",
    "        return \n",
    "    def create_samples(self, n_feat=N_FEATURES):  \n",
    "        rng = np.random.default_rng(); _frame=[0, 1]\n",
    "        \n",
    "        labels = np.ndarray(shape=(self.n_samples, 1), dtype=int)   \n",
    "        set_lbl = np.linspace(start=0, stop=self.n_centers-1, num=self.n_centers-0, dtype=int) \n",
    "        for i in range(0, self.n_samples):  \n",
    "            labels [i, 0] = rng.choice(set_lbl) \n",
    "        \n",
    "        set_avg = rng.uniform(low=_frame[0], high=_frame[1], size=(self.n_centers, n_feat)) \n",
    "        set_cvmat = np.ndarray(shape=(self.n_centers, n_feat, n_feat))   \n",
    "        for j in range(0, self.n_centers): \n",
    "            cov_ = self._semi_symm(n_feat)\n",
    "            set_cvmat [j,:,:] = cov_\n",
    "        \n",
    "        positions = np.ndarray(shape=(self.n_samples, n_feat), dtype=float)\n",
    "        for k in range(0, self.n_samples): \n",
    "            c_ = labels [k, 0]\n",
    "            cv_ = rng.multivariate_normal(mean=set_avg [c_, :], cov=set_cvmat [c_, :, :]) \n",
    "            positions[k, :] = cv_\n",
    "        self._assign_positions (positions); self._assign_labels (labels)\n",
    "        return  \n",
    "class Normal_Blobs_Identity(Sample): \n",
    "    def _assign_set_covariaces (self, set_cvmat): \n",
    "        self.set_cvmat = set_cvmat\n",
    "        return \n",
    "    def _assign_set_means (self, set_means): \n",
    "        self.set_means = set_means\n",
    "        return\n",
    "    def assign_set_obliques (self, set_thetas): \n",
    "        self.set_thetas = set_thetas \n",
    "        return \n",
    "    def create_samples(self, n_feat=N_FEATURES): \n",
    "        VARIANCE =0.01\n",
    "        rng = np.random.default_rng(); _frame=[0, 1] \n",
    "        labels = np.ndarray (shape=(self.n_samples, 1), dtype=int)   \n",
    "        set_lbl = np.linspace (start=0, stop=self.n_centers-1, num=self.n_centers-0, dtype=int) \n",
    "        for i in range (0, self.n_samples):  \n",
    "            labels [i, 0] = rng.choice (set_lbl) \n",
    "        \n",
    "        set_avg = rng.uniform (low=_frame[0], high=_frame[1], size=(self.n_centers, n_feat))  \n",
    "        set_cvmat = np.ndarray(shape=(self.n_centers, n_feat, n_feat))   \n",
    "        for j in range(0, self.n_centers): \n",
    "            set_cvmat [j,:,:] = np.eye(N=n_feat, dtype=float) * VARIANCE\n",
    "        \n",
    "        positions = np.ndarray(shape=(self.n_samples, n_feat), dtype=float)\n",
    "        for k in range(0, self.n_samples): \n",
    "            c_ = labels [k, 0]\n",
    "            cv_ = rng.multivariate_normal(mean=set_avg [c_, :], cov=set_cvmat [c_, :, :]) \n",
    "            positions[k, :] = cv_\n",
    "        self._assign_positions (positions); self._assign_labels (labels)\n",
    "        return \n",
    "class Normal_Blobs_Sizes(Sample): \n",
    "    def _assign_set_covariaces (self, set_cvmat): \n",
    "        self.set_cvmat = set_cvmat\n",
    "        return \n",
    "    def _assign_set_means (self, set_means): \n",
    "        self.set_means = set_means\n",
    "        return\n",
    "    def assign_set_obliques (self, set_thetas): \n",
    "        self.set_thetas = set_thetas \n",
    "        return \n",
    "    def create_samples(self, n_feat=N_FEATURES): \n",
    "        rng = np.random.default_rng(); _frame=[0, 1] \n",
    "        \n",
    "        MIN_CLUST_VAR = 0.0001; MAX_CLUST_VAR = 0.01\n",
    "        cluster_sizes = np.random.uniform (low=MIN_CLUST_VAR, high=MAX_CLUST_VAR, size=(self.n_centers, 1))\n",
    "        \n",
    "        labels = np.ndarray (shape=(self.n_samples, 1), dtype=int)   \n",
    "        set_lbl = np.linspace (start=0, stop=self.n_centers-1, num=self.n_centers-0, dtype=int) \n",
    "        for i in range (0, self.n_samples):  \n",
    "            labels [i, 0] = rng.choice (set_lbl) \n",
    "        \n",
    "        set_avg = rng.uniform (low=_frame[0], high=_frame[1], size=(self.n_centers, n_feat))  \n",
    "        set_cvmat = np.ndarray(shape=(self.n_centers, n_feat, n_feat))   \n",
    "        for j in range(0, self.n_centers): \n",
    "            set_cvmat [j,:,:] = np.eye(N=n_feat, dtype=float) * cluster_sizes [j, 0]\n",
    "        \n",
    "        positions = np.ndarray(shape=(self.n_samples, n_feat), dtype=float)\n",
    "        for k in range(0, self.n_samples): \n",
    "            c_ = labels [k, 0]\n",
    "            cv_ = rng.multivariate_normal(mean=set_avg [c_, :], cov=set_cvmat [c_, :, :]) \n",
    "            positions[k, :] = cv_\n",
    "        self._assign_positions (positions); self._assign_labels (labels)\n",
    "        return \n",
    "class Normal_Blobs_Sparsity(Sample): \n",
    "    def _assign_set_covariaces (self, set_cvmat): \n",
    "        self.set_cvmat = set_cvmat\n",
    "        return \n",
    "    def _assign_set_means (self, set_means): \n",
    "        self.set_means = set_means\n",
    "        return\n",
    "    def assign_set_obliques (self, set_thetas): \n",
    "        self.set_thetas = set_thetas \n",
    "        return \n",
    "    def create_samples(self, n_feat=N_FEATURES): \n",
    "        CLUSTER_VARIANCE = 0.001\n",
    "        rng = np.random.default_rng(); _frame=[0, 1] \n",
    "        to_spar = np.random.uniform(low=0, high=1, size=(N_CENTERS, 1)) \n",
    "        sparsity = to_spar / np.sum(to_spar)\n",
    "        a_lbl = np.linspace(start=0, stop=-1+self.n_centers, num=self.n_centers, dtype=int) \n",
    "        labels = rng.choice(size=(self.n_samples, 1), p=sparsity.T[0, :], a= a_lbl) \n",
    "        \n",
    "        set_avg = rng.uniform (low=_frame[0], high=_frame[1], size=(self.n_centers, n_feat))  \n",
    "        set_cvmat = np.ndarray(shape=(self.n_centers, n_feat, n_feat))   \n",
    "        for j in range(0, self.n_centers): \n",
    "            set_cvmat [j,:,:] = np.eye(N=n_feat, dtype=float) * CLUSTER_VARIANCE\n",
    "        \n",
    "        positions = np.ndarray(shape=(self.n_samples, n_feat), dtype=float)\n",
    "        for k in range(0, self.n_samples): \n",
    "            c_ = labels [k, 0]\n",
    "            cv_ = rng.multivariate_normal(mean=set_avg [c_, :], cov=set_cvmat [c_, :, :]) \n",
    "            positions[k, :] = cv_\n",
    "        self._assign_positions (positions); self._assign_labels (labels)\n",
    "        return  \n",
    "def _plot_log_likelihood(X, MIN_K, MAX_K, axsL, axsR, ll_=[], Ys=[], models=[]): \n",
    "    for it_ in range(MIN_K, MAX_K+1):\n",
    "        estimator=GaussianMixture(n_components=it_, covariance_type='full')\n",
    "        models.append(estimator)\n",
    "        labels=estimator.fit_predict(X=X)\n",
    "        ll_.append(estimator.score(X=X))\n",
    "        Ys.append(labels)\n",
    "    topScore=np.argmax(ll_)\n",
    "    bestY,bestK,bestMod=Ys[topScore],topScore+(MIN_K),models[topScore]\n",
    "    bestCov,bestMean=bestMod.covariances_,bestMod.means_\n",
    "    \n",
    "    S_=RGB_Set(n_clust=bestK) \n",
    "    S_._RGB_from_K()\n",
    "    Ctensor=S_.Ctensor_\n",
    "    \n",
    "    axsR.scatter(x=X[:,0],y=X[:,1], c=colors_from_Y(Y=bestY, RGB_in=Ctensor))\n",
    "    pocketsX = sortX(X=X, Y=bestY)\n",
    "    for it_ in range(0, bestK):\n",
    "        mean=bestMod.means_[it_,:]\n",
    "        axsR.annotate(xy=tuple(mean.flatten()), text=r\"$W[$\" + str(it_)+ r\"$]=$\" \n",
    "                      + \"%.2f\" % _intracluster_distance(X=pocketsX[it_], mean=mean, sum_=float(0)))\n",
    "        _add_ellipse(mean=mean, \n",
    "                     cov=bestMod.covariances_[it_,:,:], \n",
    "                     axs=axsR, facecolor=Ctensor[it_,:])\n",
    "        \n",
    "    axsL.scatter(y=ll_,x=np.linspace(start=MIN_K, stop=MAX_K, num=MAX_K-MIN_K+1))  \n",
    "    axsL.set_ylabel('Log Likelihood'); axsL.set_xlabel('#clusters')\n",
    "    return\n",
    "def _plot_BIC(X, MIN_K, MAX_K, axsL, axsR, bic=[], Ys=[], models=[]):\n",
    "    for it_ in range(MIN_K, MAX_K+1):\n",
    "        estimator=GaussianMixture(n_components=it_, covariance_type='full')\n",
    "        models.append(estimator)\n",
    "        labels=estimator.fit_predict(X=X)\n",
    "        bic.append(estimator.bic(X=X))\n",
    "        Ys.append(labels)\n",
    "    topScore=np.argmin(bic)\n",
    "    bestY,bestK,bestMod=Ys[topScore],topScore+(MIN_K),models[topScore]\n",
    "    bestCov,bestMean=bestMod.covariances_,bestMod.means_\n",
    "    \n",
    "    S_=RGB_Set(n_clust=bestK) \n",
    "    S_._RGB_from_K()\n",
    "    Ctensor=S_.Ctensor_\n",
    "    \n",
    "    axsR.scatter(x=X[:,0],y=X[:,1], c=colors_from_Y(Y=bestY, RGB_in=Ctensor))\n",
    "    pocketsX = sortX(X=X, Y=bestY)\n",
    "    for it_ in range(0, bestK):\n",
    "        mean=bestMod.means_[it_,:]\n",
    "        axsR.annotate(xy=tuple(mean.flatten()), text=r\"$W[$\" + str(it_)+ r\"$]=$\" \n",
    "                      + \"%.2f\" % _intracluster_distance(X=pocketsX[it_], mean=mean, sum_=float(0)))\n",
    "        _add_ellipse(mean=mean, \n",
    "                     cov=bestMod.covariances_[it_,:,:], \n",
    "                     axs=axsR, facecolor=Ctensor[it_,:])\n",
    "        \n",
    "    axsL.scatter(y=bic,x=np.linspace(start=MIN_K, stop=MAX_K, num=MAX_K-MIN_K+1))  \n",
    "    axsL.set_ylabel('BIC'); axsL.set_xlabel('#clusters')\n",
    "    return\n",
    "def _plot_AIC(X, MIN_K, MAX_K, axsL, axsR, aic=[], Ys=[], models=[]):\n",
    "    for it_ in range(MIN_K, MAX_K+1):\n",
    "        estimator=GaussianMixture(n_components=it_, covariance_type='full')\n",
    "        models.append(estimator)\n",
    "        labels=estimator.fit_predict(X=X)\n",
    "        aic.append(estimator.aic(X=X))\n",
    "        Ys.append(labels)\n",
    "    topScore=np.argmin(aic)\n",
    "    bestY,bestK,bestMod=Ys[topScore],topScore+(MIN_K),models[topScore]\n",
    "    bestCov,bestMean=bestMod.covariances_,bestMod.means_\n",
    "    \n",
    "    S_=RGB_Set(n_clust=bestK) \n",
    "    S_._RGB_from_K()\n",
    "    Ctensor=S_.Ctensor_\n",
    "    \n",
    "    axsR.scatter(x=X[:,0],y=X[:,1], c=colors_from_Y(Y=bestY, RGB_in=Ctensor))\n",
    "    pocketsX = sortX(X=X, Y=bestY)\n",
    "    for it_ in range(0, bestK):\n",
    "        mean=bestMod.means_[it_,:]\n",
    "        axsR.annotate(xy=tuple(mean.flatten()), text=r\"$W[$\" + str(it_)+ r\"$]=$\" \n",
    "                      + \"%.2f\" % _intracluster_distance(X=pocketsX[it_], mean=mean, sum_=float(0)))\n",
    "        _add_ellipse(mean=mean, \n",
    "                     cov=bestMod.covariances_[it_,:,:], \n",
    "                     axs=axsR, facecolor=Ctensor[it_,:])\n",
    "        \n",
    "    axsL.scatter(y=aic,x=np.linspace(start=MIN_K, stop=MAX_K, num=MAX_K-MIN_K+1))  \n",
    "    axsL.set_ylabel('AIC'); axsL.set_xlabel('#clusters')\n",
    "    return\n",
    "def _plot_silhouette(X, MIN_K, MAX_K, axsL, axsR, sihouette=[], Ys=[], models=[]):\n",
    "    for it_ in range(MIN_K, MAX_K+1):\n",
    "        estimator=GaussianMixture(n_components=it_, covariance_type='full')\n",
    "        models.append(estimator)\n",
    "        labels=estimator.fit_predict(X=X)\n",
    "        sihouette.append(silhouette_score(X=X, labels=labels))\n",
    "        Ys.append(labels)\n",
    "    topScore=np.argmax(sihouette)\n",
    "    bestY,bestK,bestMod=Ys[topScore],topScore+(MIN_K),models[topScore]\n",
    "    bestCov,bestMean=bestMod.covariances_,bestMod.means_\n",
    "    \n",
    "    S_=RGB_Set(n_clust=bestK) \n",
    "    S_._RGB_from_K()\n",
    "    Ctensor=S_.Ctensor_\n",
    "    \n",
    "    axsR.scatter(x=X[:,0],y=X[:,1], c=colors_from_Y(Y=bestY, RGB_in=Ctensor))\n",
    "    pocketsX = sortX(X=X, Y=bestY)\n",
    "    for it_ in range(0, bestK):\n",
    "        mean=bestMod.means_[it_,:]\n",
    "        axsR.annotate(xy=tuple(mean.flatten()), text=r\"$W[$\" + str(it_)+ r\"$]=$\" \n",
    "                      + \"%.2f\" % _intracluster_distance(X=pocketsX[it_], mean=mean, sum_=float(0)))\n",
    "        _add_ellipse(mean=mean, \n",
    "                     cov=bestMod.covariances_[it_,:,:], \n",
    "                     axs=axsR, facecolor=Ctensor[it_,:])\n",
    "    \n",
    "    axsL.scatter(y=sihouette,x=np.linspace(start=MIN_K, stop=MAX_K, num=MAX_K-MIN_K+1))  \n",
    "    axsL.set_ylabel('silhouette'); axsL.set_xlabel('#clusters')\n",
    "    return\n",
    "def sortX(X, Y): \n",
    "    assert(X.shape[0]==Y.shape[0])\n",
    "    lenY=Y.shape[0]; n_mix=np.unique(Y).size \n",
    "    pockets=[None] * n_mix\n",
    "    for iter_0 in range(0, n_mix):\n",
    "        stackX = X[0:1,:]\n",
    "        for iter_1 in range(0, lenY):\n",
    "            tag=Y[iter_1]\n",
    "            if iter_0 == tag:\n",
    "                apX=X[iter_1:iter_1+1,:] \n",
    "                stackX = np.concatenate((stackX, apX), axis=0)\n",
    "        pockets[iter_0]=stackX[1:,]\n",
    "    return pockets\n",
    "def _intracluster_distance(X, mean, sum_=float(0)):\n",
    "    for row in X: \n",
    "        sum_ += np.linalg.norm(row.T - mean.flatten())\n",
    "    return sum_/X.shape[0] \n",
    "def _add_ellipse(axs, mean, cov, facecolor, SCALE=5.99):\n",
    "    eVal, eVec=np.linalg.eig(a=cov)  \n",
    "    ratio=eVec[1,0]/eVec[1,1]\n",
    "    scaled_eVal=np.sqrt(eVal*SCALE)*2\n",
    "    elp=Ellipse(xy=tuple(mean.flatten()), angle=np.arctan(ratio)* 180 / np.pi,\n",
    "                width=scaled_eVal[0], height=scaled_eVal[1],fc=facecolor)\n",
    "    axs.add_patch(elp).set_alpha(0.40)\n",
    "    return\n",
    "def colors_from_Y(Y, RGB_in, DIM_RGB=3): \n",
    "    colors = np.ndarray(shape=(Y.shape[0], DIM_RGB), dtype=float)\n",
    "    for it_ in range(0, Y.shape[0]): \n",
    "        tag_=Y[it_]\n",
    "        colors[it_,:] = RGB_in[tag_,:]\n",
    "    return colors\n",
    "class RGB_Set: \n",
    "    def __init__(self, n_clust):\n",
    "        self.n_clust=n_clust \n",
    "        pass\n",
    "    def _RGB_from_K(self,DIM_RBG=3): \n",
    "        rng=np.random.default_rng()\n",
    "        self.Ctensor_=rng.integers(low=0,high=256,size=(self.n_clust, DIM_RBG)) /256\n",
    "        return \n",
    "def plot_metrics(X, MIN_K=2, MAX_K=10): \n",
    "    fig, axs=pyplot.subplots(nrows=2,ncols=3) \n",
    "    fig.patch.set_facecolor ('#E0E0E0') \n",
    "    pyplot.subplots_adjust(right=1.5, wspace=.50, hspace=0.3, top=1)\n",
    "    _plot_silhouette(X=X,MIN_K=MIN_K,MAX_K=MAX_K,axsL=axs[0,0],axsR=axs[1,0])\n",
    "    _plot_AIC(X=X,MIN_K=MIN_K,MAX_K=MAX_K,axsL=axs[0,1], axsR=axs[1,1])\n",
    "    _plot_BIC(X=X,MIN_K=MIN_K,MAX_K=MAX_K,axsL=axs[0,2], axsR=axs[1,2])\n",
    "    pyplot.show(); pyplot.close()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "international-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _empirical_mean(X:np.ndarray): \n",
    "    return np.sum(X)/X.size \n",
    "class Visual():  \n",
    "    def createSamCopies(self, batchsize, n_copies):  \n",
    "        (blobs:=Normal_Blobs_Full(n_samples=batchsize)).create_samples() \n",
    "        self.X=np.zeros(shape=(n_copies,blobs.positions.shape[0],blobs.positions.shape[1]))\n",
    "        for i in range(0,n_copies):  \n",
    "            self.X[i,:,:]= blobs.positions\n",
    "        return\n",
    "    def run(self, range_mix:tuple, measurement='aic'):\n",
    "        #init metric schemes\n",
    "        self.range_mix=range_mix\n",
    "        #GMM copies x blobs  \n",
    "        n_mix=1+range_mix[1]-range_mix[0]\n",
    "        n_copies=self.X.shape[0]\n",
    "        metrics=np.ndarray(shape=(n_mix,n_copies))\n",
    "        for mix_ in range(0,n_mix): \n",
    "            for i in range(0,n_copies):\n",
    "                self.mixer=GaussianMixture(n_components=mix_+range_mix[0],random_state=0)\n",
    "                labels=self.mixer.fit_predict(X=self.X[i,:,:])\n",
    "                metrics[mix_,i]=self._calculate_metric(X=self.X[i,:,:],labels=labels,measurement=measurement)\n",
    "\n",
    "        # empiracal mean silhouettes\n",
    "        self.mean_silhouttes=np.ndarray(shape=(1,n_mix))\n",
    "        for i in range(0, n_mix):\n",
    "            self.mean_silhouttes[0,i]=_empirical_mean(X=metrics[i,:])\n",
    "        return \n",
    "    def _calculate_metric(self,X,labels,measurement:str): \n",
    "        if measurement=='silhouette': metric_=silhouette_score(X=X,labels=labels)\n",
    "        elif measurement=='aic': metric_= self.mixer.aic(X) \n",
    "        elif measurement=='bic': metric_=self.mixer.bic(X)\n",
    "        return metric_\n",
    "(charter:=Visual()).createSamCopies(batchsize=100,n_copies=10) \n",
    "charter.run(range_mix=(3,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
